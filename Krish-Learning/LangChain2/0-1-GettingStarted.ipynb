{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb7b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001A2CCA40B90> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A2CCA40F50> root_client=<openai.OpenAI object at 0x000001A2CCA402D0> root_async_client=<openai.AsyncOpenAI object at 0x000001A2CCA41090> model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "## Langsmith tracking. \n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfbd5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a type of artificial intelligence that has the ability to create new content or data that is original and not based on existing examples. This can include generating text, images, music, or other types of content. Generative AI uses techniques such as neural networks and deep learning algorithms to generate new and unique content based on the patterns and data it has been trained on.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 13, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CIYSWTOKCnT8J4umhqHPkekQ48Oeb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--ef02deba-4e97-4b6f-ab35-bc10e5145cbe-0' usage_metadata={'input_tokens': 13, 'output_tokens': 77, 'total_tokens': 90, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## Input to LLM. \n",
    "result=llm.invoke(\"What is Generative AI?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a8c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt Templates. \n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are an expert AI engineer, provide me answers based on these questions\"),\n",
    "    (\"user\",\"{input}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5aa52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain is a concept that refers to a blockchain platform designed for hosting and executing smart contracts written in multiple programming languages. Traditional blockchain platforms like Ethereum typically require developers to write smart contracts in a specific language like Solidity. However, LangChain aims to provide more flexibility by allowing developers to write smart contracts in a wide range of programming languages, such as Python, JavaScript, or Java.\\n\\nBy supporting multiple programming languages, LangChain opens up the world of blockchain development to a larger pool of developers who may already be familiar with a particular programming language. This lowers the barrier to entry for developers looking to build decentralized applications (dApps) on the blockchain.\\n\\nLangChain achieves this multi-language support through various mechanisms, such as using transpilers to convert code written in different languages into a common bytecode format that can be executed on the blockchain. Additionally, LangChain may provide SDKs (Software Development Kits) and libraries for different languages to assist developers in building and deploying their smart contracts seamlessly.\\n\\nIn summary, LangChain is a concept that aims to enhance the accessibility and flexibility of blockchain development by allowing smart contracts to be written in multiple programming languages, ultimately enabling a more diverse and inclusive ecosystem of decentralized applications.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 240, 'prompt_tokens': 35, 'total_tokens': 275, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CIYZflZL5CMeMsGiifN7AIPImWOiK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--e6159d0e-b687-483d-881a-abf95b7d80e7-0' usage_metadata={'input_tokens': 35, 'output_tokens': 240, 'total_tokens': 275, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## User the model and promopt template together.\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"input\":\"Explain the concept of LangChain in detail.\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be5d3567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make tea, follow these steps:\n",
      "\n",
      "1. Boil water in a kettle or pot.\n",
      "2. Place a tea bag or loose tea leaves in a cup or teapot.\n",
      "3. Pour the hot water over the tea.\n",
      "4. Let the tea steep for the recommended time (usually 3-5 minutes for black tea, 1-3 minutes for green tea).\n",
      "5. Remove the tea bag or strain out the loose leaves.\n",
      "6. Add any desired sweeteners or milk.\n",
      "7. Stir and enjoy your tea!\n"
     ]
    }
   ],
   "source": [
    "type(response)\n",
    "\n",
    "## String output parser \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "outputparser = StrOutputParser() \n",
    "\n",
    "chain = prompt | llm | outputparser\n",
    "response = chain.invoke({\"input\":\"How to make tea.\"})\n",
    "print(response)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
