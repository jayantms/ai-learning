{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "951025b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd82482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS \n",
    "from langchain_openai import OpenAIEmbeddings \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70c49715",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/workflows/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/how-tos/map-reduce/\"\n",
    "]\n",
    "\n",
    "langchain_urls=[\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "    \"https://python.langchain.com/docs/tutorials/chatbot/\",\n",
    "    \"https://python.langchain.com/docs/tutorials/qa_chat_history/\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1ce9db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[WebBaseLoader(urls).load() for url in urls]\n",
    "docs_langchain=[WebBaseLoader(langchain_urls).load() for url in langchain_urls]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9d4b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list=[item for sublist in docs for item in sublist]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "doc_splits = text_splitter.split_documents(doc_list)\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=doc_splits, \n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "##------------------------ \n",
    "\n",
    "doc_list_langchain=[item for sublist in docs_langchain for item in sublist]\n",
    "text_splitter_langchain = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "doc_splits_langchain = text_splitter_langchain.split_documents(doc_list_langchain)\n",
    "\n",
    "vectorstore_langchain = FAISS.from_documents(\n",
    "    documents=doc_splits_langchain, \n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "retriever_langchain = vectorstore_langchain.as_retriever()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61267e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='3754bc53-2fbb-426b-9d88-4e70b24f0fa5', metadata={'source': 'https://python.langchain.com/docs/tutorials/chatbot/', 'title': 'Build a Chatbot | ü¶úÔ∏èüîó LangChain', 'description': 'This tutorial previously used the RunnableWithMessageHistory abstraction. You can access that version of the documentation in the v0.2 docs.', 'language': 'en'}, page_content='So how do we best implement this?\\nMessage persistence\\u200b\\nLangGraph implements a built-in persistence layer, making it ideal for chat applications that support multiple conversational turns.\\nWrapping our chat model in a minimal LangGraph application allows us to automatically persist the message history, simplifying the development of multi-turn applications.\\nLangGraph comes with a simple in-memory checkpointer, which we use below. See its documentation for more detail, including how to use different persistence backends (e.g., SQLite or Postgres).'),\n",
       " Document(id='be69b95a-d63d-4f59-b4d6-0db75a85024b', metadata={'source': 'https://python.langchain.com/docs/tutorials/chatbot/', 'title': 'Build a Chatbot | ü¶úÔ∏èüîó LangChain', 'description': 'This tutorial previously used the RunnableWithMessageHistory abstraction. You can access that version of the documentation in the v0.2 docs.', 'language': 'en'}, page_content='So how do we best implement this?\\nMessage persistence\\u200b\\nLangGraph implements a built-in persistence layer, making it ideal for chat applications that support multiple conversational turns.\\nWrapping our chat model in a minimal LangGraph application allows us to automatically persist the message history, simplifying the development of multi-turn applications.\\nLangGraph comes with a simple in-memory checkpointer, which we use below. See its documentation for more detail, including how to use different persistence backends (e.g., SQLite or Postgres).'),\n",
       " Document(id='7fe07f77-9f0d-4aa8-aba9-f7fe9152ab8c', metadata={'source': 'https://python.langchain.com/docs/tutorials/chatbot/', 'title': 'Build a Chatbot | ü¶úÔ∏èüîó LangChain', 'description': 'This tutorial previously used the RunnableWithMessageHistory abstraction. You can access that version of the documentation in the v0.2 docs.', 'language': 'en'}, page_content='So how do we best implement this?\\nMessage persistence\\u200b\\nLangGraph implements a built-in persistence layer, making it ideal for chat applications that support multiple conversational turns.\\nWrapping our chat model in a minimal LangGraph application allows us to automatically persist the message history, simplifying the development of multi-turn applications.\\nLangGraph comes with a simple in-memory checkpointer, which we use below. See its documentation for more detail, including how to use different persistence backends (e.g., SQLite or Postgres).'),\n",
       " Document(id='5067e74d-78a4-41f0-8021-4dfc4d4253e2', metadata={'source': 'https://python.langchain.com/docs/tutorials/qa_chat_history/', 'title': 'Build a Retrieval Augmented Generation (RAG) App: Part 2 | ü¶úÔ∏èüîó LangChain', 'description': 'In many Q&A applications we want to allow the user to have a back-and-forth conversation, meaning the application needs some sort of \"memory\" of past questions and answers, and some logic for incorporating those into its current thinking.', 'language': 'en'}, page_content='LangGraph implements a built-in persistence layer, making it ideal for chat applications that support multiple conversational turns.\\nTo manage multiple conversational turns and threads, all we have to do is specify a checkpointer when compiling our application. Because the nodes in our graph are appending messages to the state, we will retain a consistent chat history across invocations.\\nLangGraph comes with a simple in-memory checkpointer, which we use below. See its documentation for more detail, including how to use different persistence backends (e.g., SQLite or Postgres).\\nFor a detailed walkthrough of how to manage message history, head to the How to add message history (memory) guide.\\nfrom langgraph.checkpoint.memory import MemorySavermemory = MemorySaver()graph = graph_builder.compile(checkpointer=memory)# Specify an ID for the threadconfig = {\"configurable\": {\"thread_id\": \"abc123\"}}API Reference:MemorySaver\\nWe can now invoke similar to before:')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is LangGraph?\")\n",
    "retriever_langchain.invoke(\"What is LangGraph?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2345a566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='retriever_vector_db_blog', description='Search and run information about LangChain.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002468EA2D8A0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000246E81D83E0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002468EA2D9E0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000246E81D83E0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Retriver to Retriever Tool. \n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool_langgraph = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name=\"retriever_vector_db_blog\",\n",
    "    description=\"Search and run information about LangGraph.\"\n",
    ")\n",
    "\n",
    "retriever_tool_langchain = create_retriever_tool(\n",
    "    retriever=retriever_langchain,\n",
    "    name=\"retriever_vector_db_blog\",\n",
    "    description=\"Search and run information about LangChain.\"\n",
    ")\n",
    "\n",
    "retriever_tool_langgraph \n",
    "retriever_tool_langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18e60c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool_langgraph, retriever_tool_langchain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46737b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Langgraph Workflows - \n",
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92e1ac4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 36, 'total_tokens': 59, 'completion_time': 0.023122226, 'prompt_time': 0.002655195, 'queue_time': 0.2041839, 'total_time': 0.025777421}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_90c2e79dab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--b7674c9a-a49e-49ef-be7c-d6bc11fa5aac-0', usage_metadata={'input_tokens': 36, 'output_tokens': 23, 'total_tokens': 59})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "llm.invoke(\"Hi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e1af627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9d4f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c09aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edges\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # Data model\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance check.\"\"\"\n",
    "\n",
    "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM\n",
    "    model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "    # LLM with tool and validation\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(score)\n",
    "        return \"rewrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed2ff5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated message\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    docs = last_message.content\n",
    "\n",
    "    # Prompt\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    # LLM\n",
    "    llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "    # Post-processing\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # Chain\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4d425a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Grader\n",
    "    model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42980882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", agent)  # agent\n",
    "retrieve = ToolNode([retriever_tool_langgraph,retriever_tool_langchain])\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
    "workflow.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
    "workflow.add_node(\n",
    "    \"generate\", generate\n",
    ")  # Generating a response after we know the documents are relevant\n",
    "# Call agent node to decide to retrieve or not\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called.\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # Assess agent decision\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6498e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS RELEVANT---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is LangGraph?', additional_kwargs={}, response_metadata={}, id='dc82b2a2-49ce-4f44-a64f-a5bad1afb52b'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8kjrggen9', 'function': {'arguments': '{\"query\":\"LangGraph definition\"}', 'name': 'retriever_vector_db_blog'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 308, 'total_tokens': 328, 'completion_time': 0.025045264, 'prompt_time': 0.018571768, 'queue_time': 0.203656086, 'total_time': 0.043617032}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_90c2e79dab', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--51a042b6-8bbc-40d1-b81e-3e5c02bb2125-0', tool_calls=[{'name': 'retriever_vector_db_blog', 'args': {'query': 'LangGraph definition'}, 'id': '8kjrggen9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 308, 'output_tokens': 20, 'total_tokens': 328}),\n",
       "  ToolMessage(content='LangGraph implements a built-in persistence layer, making it ideal for chat applications that support multiple conversational turns.\\nTo manage multiple conversational turns and threads, all we have to do is specify a checkpointer when compiling our application. Because the nodes in our graph are appending messages to the state, we will retain a consistent chat history across invocations.\\nLangGraph comes with a simple in-memory checkpointer, which we use below. See its documentation for more detail, including how to use different persistence backends (e.g., SQLite or Postgres).\\nFor a detailed walkthrough of how to manage message history, head to the How to add message history (memory) guide.\\nfrom langgraph.checkpoint.memory import MemorySavermemory = MemorySaver()graph = graph_builder.compile(checkpointer=memory)# Specify an ID for the threadconfig = {\"configurable\": {\"thread_id\": \"abc123\"}}API Reference:MemorySaver\\nWe can now invoke similar to before:\\n\\nLangGraph implements a built-in persistence layer, making it ideal for chat applications that support multiple conversational turns.\\nTo manage multiple conversational turns and threads, all we have to do is specify a checkpointer when compiling our application. Because the nodes in our graph are appending messages to the state, we will retain a consistent chat history across invocations.\\nLangGraph comes with a simple in-memory checkpointer, which we use below. See its documentation for more detail, including how to use different persistence backends (e.g., SQLite or Postgres).\\nFor a detailed walkthrough of how to manage message history, head to the How to add message history (memory) guide.\\nfrom langgraph.checkpoint.memory import MemorySavermemory = MemorySaver()graph = graph_builder.compile(checkpointer=memory)# Specify an ID for the threadconfig = {\"configurable\": {\"thread_id\": \"abc123\"}}API Reference:MemorySaver\\nWe can now invoke similar to before:\\n\\nLangGraph implements a built-in persistence layer, making it ideal for chat applications that support multiple conversational turns.\\nTo manage multiple conversational turns and threads, all we have to do is specify a checkpointer when compiling our application. Because the nodes in our graph are appending messages to the state, we will retain a consistent chat history across invocations.\\nLangGraph comes with a simple in-memory checkpointer, which we use below. See its documentation for more detail, including how to use different persistence backends (e.g., SQLite or Postgres).\\nFor a detailed walkthrough of how to manage message history, head to the How to add message history (memory) guide.\\nfrom langgraph.checkpoint.memory import MemorySavermemory = MemorySaver()graph = graph_builder.compile(checkpointer=memory)# Specify an ID for the threadconfig = {\"configurable\": {\"thread_id\": \"abc123\"}}API Reference:MemorySaver\\nWe can now invoke similar to before:\\n\\nSo how do we best implement this?\\nMessage persistence\\u200b\\nLangGraph implements a built-in persistence layer, making it ideal for chat applications that support multiple conversational turns.\\nWrapping our chat model in a minimal LangGraph application allows us to automatically persist the message history, simplifying the development of multi-turn applications.\\nLangGraph comes with a simple in-memory checkpointer, which we use below. See its documentation for more detail, including how to use different persistence backends (e.g., SQLite or Postgres).', name='retriever_vector_db_blog', id='20765552-4da6-4042-8808-be0aa645ea0e', tool_call_id='8kjrggen9'),\n",
       "  HumanMessage(content='LangGraph is a tool that implements a built-in persistence layer, making it ideal for chat applications that support multiple conversational turns. It retains a consistent chat history across invocations by appending messages to the state. LangGraph comes with a simple in-memory checkpointer and supports various persistence backends.', additional_kwargs={}, response_metadata={}, id='4937fc2e-4313-49aa-9e4a-a14d55f399e2')]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"What is LangGraph?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc837abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS RELEVANT---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is LangChain?', additional_kwargs={}, response_metadata={}, id='c73181b2-7d0d-4eb0-bc6f-61aea28e4174'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'ffnpje8hr', 'function': {'arguments': '{\"query\":\"LangChain\"}', 'name': 'retriever_vector_db_blog'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 308, 'total_tokens': 327, 'completion_time': 0.023841607, 'prompt_time': 0.01694492, 'queue_time': 0.204259165, 'total_time': 0.040786527}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_50a6be1b6f', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4d2c2092-ed64-40bc-8096-12f16ce0e145-0', tool_calls=[{'name': 'retriever_vector_db_blog', 'args': {'query': 'LangChain'}, 'id': 'ffnpje8hr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 308, 'output_tokens': 19, 'total_tokens': 327}),\n",
       "  ToolMessage(content='Tutorials | ü¶úÔ∏èüîó LangChain\\n\\nTutorials | ü¶úÔ∏èüîó LangChain\\n\\nTutorials | ü¶úÔ∏èüîó LangChain\\n\\nSkip to main contentThese docs will be deprecated and no longer maintained with the release of LangChain v1.0 in October 2025. Visit the v1.0 alpha docsIntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1üí¨SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation', name='retriever_vector_db_blog', id='82f198c5-adeb-4960-9ad8-9cce0853b0a4', tool_call_id='ffnpje8hr'),\n",
       "  HumanMessage(content='LangChain is a suite of tools and libraries used to build conversational AI applications. It provides a range of functions, including chain management, vector stores, and semantic layers, to help developers create sophisticated chatbots and question-answering systems. LangChain supports integration with various databases and models, including graph and SQL databases, and large language models.', additional_kwargs={}, response_metadata={}, id='17d869f1-49e1-4ee1-9f93-39762c60f9b0')]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5924bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is Machine Learning?', additional_kwargs={}, response_metadata={}, id='d0830504-f9c7-4058-a832-b00a150d6dd7'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'my9nacbk0', 'function': {'arguments': '{\"query\":\"Machine Learning definition\"}', 'name': 'retriever_vector_db_blog'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 308, 'total_tokens': 328, 'completion_time': 0.028907606, 'prompt_time': 0.017024081, 'queue_time': 0.203386491, 'total_time': 0.045931687}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_90c2e79dab', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--07011a8e-e5c9-4816-b50a-9a1c78dafa00-0', tool_calls=[{'name': 'retriever_vector_db_blog', 'args': {'query': 'Machine Learning definition'}, 'id': 'my9nacbk0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 308, 'output_tokens': 20, 'total_tokens': 328}),\n",
       "  ToolMessage(content='a classifier (via a prompt) or majority vote.Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.Source: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}Content: Fig. 1. Overview of a LLM-powered autonomous agent system.Component One: Planning#A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.Task Decomposition#Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking\\n\\na classifier (via a prompt) or majority vote.Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.Source: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}Content: Fig. 1. Overview of a LLM-powered autonomous agent system.Component One: Planning#A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.Task Decomposition#Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking\\n\\na classifier (via a prompt) or majority vote.Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.Source: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}Content: Fig. 1. Overview of a LLM-powered autonomous agent system.Component One: Planning#A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.Task Decomposition#Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking\\n\\neach state evaluated by a classifier (via a prompt) or majority vote.Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.Source: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}Content: Fig. 1. Overview of a LLM-powered autonomous agent system.Component One: Planning#A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.Task Decomposition#Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking', name='retriever_vector_db_blog', id='9842c234-62d6-46cd-86cd-4b9e72816c70', tool_call_id='my9nacbk0'),\n",
       "  AIMessage(content='The initial question is quite broad and can be interpreted in many ways. To formulate an improved question, let\\'s break it down into more specific aspects:\\n\\n1. **Definition and scope**: Do you want to know the definition of Machine Learning, or its scope and applications?\\n2. **History and evolution**: Are you interested in the history of Machine Learning, its evolution, and key milestones?\\n3. **Types and subfields**: Do you want to know about the different types of Machine Learning (e.g., supervised, unsupervised, reinforcement learning) and their subfields (e.g., deep learning, natural language processing)?\\n4. **Key concepts and techniques**: Are you looking for an explanation of fundamental concepts and techniques in Machine Learning, such as regression, classification, clustering, neural networks, and optimization algorithms?\\n5. **Applications and industries**: Do you want to know about the various applications of Machine Learning in industries such as healthcare, finance, marketing, or transportation?\\n6. **Current trends and future directions**: Are you interested in staying up-to-date with the latest developments and future directions in Machine Learning research and development?\\n\\nWith these aspects in mind, an improved question could be:\\n\\n**\"What are the fundamental concepts, key techniques, and current applications of Machine Learning, and how is it being used to drive innovation in various industries?\"**\\n\\nThis revised question is more specific and allows for a more detailed and relevant response.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 288, 'prompt_tokens': 81, 'total_tokens': 369, 'completion_time': 0.569561075, 'prompt_time': 0.006482536, 'queue_time': 0.20295626, 'total_time': 0.576043611}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_a7a2f9abbf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--126ab228-e6dc-42aa-a289-744fd7ad4a39-0', usage_metadata={'input_tokens': 81, 'output_tokens': 288, 'total_tokens': 369}),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 1508, 'total_tokens': 1509, 'completion_time': 0.003314917, 'prompt_time': 0.083714412, 'queue_time': None, 'total_time': 0.087029329}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_a7a2f9abbf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--15815834-0f72-4a67-a6db-70abe81ee510-0', usage_metadata={'input_tokens': 1508, 'output_tokens': 1, 'total_tokens': 1509})]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"What is Machine Learning?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
