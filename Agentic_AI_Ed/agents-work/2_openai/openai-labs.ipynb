{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a3517b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv \n",
    "from agents import Agent, Runner, trace \n",
    "import asyncio\n",
    "\n",
    "load_dotenv(override=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26b1c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lab1\n",
    "agent = Agent(name=\"JokeTeller\", instructions=\"You are a joke teller\", model = \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "191a6d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don‚Äôt skeletons fight each other?  \n",
      "\n",
      "Because they don‚Äôt have the guts!\n"
     ]
    }
   ],
   "source": [
    "with trace(\"Joke Teller\"):\n",
    "    result =  await Runner.run(agent, \"Tell me a joke\")\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "237ce768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lab2\n",
    "import os \n",
    "import sendgrid\n",
    "from sendgrid.helpers.mail import Mail, Email, To, Content\n",
    "\n",
    "load_dotenv(override=True) \n",
    "api_key=os.environ.get('SENDGRID_API_KEY')\n",
    "api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7f66ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    }
   ],
   "source": [
    "def send_test_email():\n",
    "    sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "    from_email = Email(\"jayantms@gmail.com\")  # Change to your verified sender\n",
    "    to_email = To(\"jayantms@gmail.com\")  # Change to your recipient\n",
    "    content = Content(\"text/plain\", \"This is an important test email\")\n",
    "    mail = Mail(from_email, to_email, \"Test email\", content).get()\n",
    "    response = sg.client.mail.send.post(request_body=mail)\n",
    "    print(response.status_code)\n",
    "\n",
    "send_test_email()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "22d0fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agents Workflows - \n",
    "\n",
    "instructions1 = \"You are a sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write professional, serious cold emails.\"\n",
    "\n",
    "instructions2 = \"You are a humorous, engaging sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write witty, engaging cold emails that are likely to get a response.\"\n",
    "\n",
    "instructions3 = \"You are a busy sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write concise, to the point cold emails.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_agent1 = Agent(name=\"Progessional Sales Agent\", instructions = instructions1, model = \"gpt-4o-mini\")\n",
    "sales_agent2 = Agent(name=\"Engaging Sales Agent\", instructions = instructions2, model = \"gpt-4o-mini\")\n",
    "sales_agent3 = Agent(name=\"Busy Sales Agent\", instructions = instructions3, model = \"gpt-4o-mini\")\n",
    "\n",
    "#tools = [agent1, agent2, agent3] \n",
    "message = \"Write a cold sales email\"\n",
    "\n",
    "#for tool in tools: \n",
    "#    Runner.run(tool)\n",
    "\n",
    "results = await asyncio.gather(\n",
    "    Runner.run(sales_agent1, message), \n",
    "    Runner.run(sales_agent2, message), \n",
    "    Runner.run(sales_agent3, message)\n",
    ")\n",
    "\n",
    "outputs = [result.final_output for result in results]\n",
    "\n",
    "# print(\"Number of messages - \", len(outputs))\n",
    "# for output in outputs: \n",
    "#     print(\"--------------------------------------------\")\n",
    "#     print(output)\n",
    "\n",
    "\n",
    "##------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f2b36f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best email answer - Subject: Let‚Äôs Make Your SOC 2 Compliance as Easy as Pie (Because Who Doesn‚Äôt Love Pie?)\n",
      "\n",
      "Hey [First Name],\n",
      "\n",
      "I hope this email finds you well! I wanted to drop you a quick note, not to sell you a used car or serenade you with the ‚Äúgreatest hits of GDPR compliance,‚Äù but to introduce you to something truly delightful: ComplAI! üéâ\n",
      "\n",
      "Now, I know what you‚Äôre thinking: ‚ÄúAnother compliance tool? Yawn.‚Äù But hang on! Our platform is like a superhero for your SOC 2 compliance ‚Äì swooping in with AI-powered magic that turns the mind-numbing audit process into something as simple as scoring free pizza on a Friday.\n",
      "\n",
      "Imagine this: No more diving into a sea of spreadsheets, wrestling with complex regulations, or fielding alarms from auditors like they're pesky insects. ComplAI does the heavy lifting so you can focus on what really matters‚Äîlike trying to figure out how to apply the simultaneous equations of coffee consumption and nap time (or growing your business).\n",
      "\n",
      "Curious? I‚Äôd love to schedule a quick 15-minute chat to show you how we can turn your compliance headaches into happy dances. Let me know when you‚Äôre free‚Äîbonus points for sharing your favorite pizza topping!\n",
      "\n",
      "Looking forward to it!\n",
      "\n",
      "Best,  \n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "ComplAI  \n"
     ]
    }
   ],
   "source": [
    "salesPicker = Agent(name=\"SalesPicker\", instructions=\"You pick the best cold sales email from the given options. \\\n",
    "Imagine you are a customer and pick the one you are most likely to respond to. \\\n",
    "Do not give an explanation; reply with the selected email only.\", model = \"gpt-4o-mini\")\n",
    "\n",
    "with trace(\"Selection from sales people\"):\n",
    "    results = await asyncio.gather(\n",
    "        Runner.run(agent1, message), \n",
    "        Runner.run(agent2, message), \n",
    "        Runner.run(agent3, message)\n",
    "    )\n",
    "\n",
    "    outputs = [result.final_output for result in results]\n",
    "\n",
    "    coldsalesemail = \"Cold sales emails:\\n\\n\" + \"\\n\\nEmail:\\n\\n\".join(outputs)\n",
    "    \n",
    "    resultmsg = await Runner.run(salesPicker, coldsalesemail)\n",
    "    print(f\"Best email answer - {resultmsg.final_output}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8540b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Agents as a Tool.\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace, function_tool\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from typing import Dict\n",
    "import sendgrid\n",
    "import os\n",
    "from sendgrid.helpers.mail import Mail, Email, To, Content\n",
    "import asyncio\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def send_email(body: str):\n",
    "    \"\"\" Send out an email with the given body to all sales prospects \"\"\"\n",
    "    sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "    from_email = Email(\"jayantms@gmail.com\")  # Change to your verified sender\n",
    "    to_email = To(\"jayantms@gmail.com\")  # Change to your recipient\n",
    "    content = Content(\"text/plain\", body)\n",
    "    mail = Mail(from_email, to_email, \"Sales email\", content).get()\n",
    "    sg.client.mail.send.post(request_body=mail)\n",
    "    return {\"status\": \"success\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad182e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool1 = sales_agent1.as_tool(tool_name=\"sales_agent1\", tool_description=message)\n",
    "tool2 = sales_agent2.as_tool(tool_name=\"sales_agent2\", tool_description=message)\n",
    "tool3 = sales_agent3.as_tool(tool_name=\"sales_agent3\", tool_description=message)\n",
    "\n",
    "tools = [tool1, tool2, tool3, send_email] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d15b2af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You are a Sales Manager at ComplAI. Your goal is to find the single best cold sales email using the sales_agent tools.\n",
    " \n",
    "Follow these steps carefully:\n",
    "1. Generate Drafts: Use all three sales_agent tools to generate three different email drafts. Do not proceed until all three drafts are ready.\n",
    " \n",
    "2. Evaluate and Select: Review the drafts and choose the single best email using your judgment of which one is most effective.\n",
    " \n",
    "3. Use the send_email tool to send the best email (and only the best email) to the user.\n",
    " \n",
    "Crucial Rules:\n",
    "- You must use the sales agent tools to generate the drafts ‚Äî do not write them yourself.\n",
    "- You must send ONE email using the send_email tool ‚Äî never more than one.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sales_manager = Agent(name=\"Sales Manager\", instructions=instructions, tools=tools, model=\"gpt-4o-mini\")\n",
    "\n",
    "message = \"Send a cold sales email addressed to 'Dear CEO'\"\n",
    "\n",
    "with trace(\"Sales manager\"):\n",
    "    result = await Runner.run(sales_manager, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb188f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3e531a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionTool(name='Subject Writer', description='Write a subject for cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'Subject Writer_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x0000013FD8A242C0>, strict_json_schema=True, is_enabled=True),\n",
       " FunctionTool(name='Html convertor', description='Convert a text email body to an HTML email body', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'Html convertor_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x0000013FD8A07EC0>, strict_json_schema=True, is_enabled=True),\n",
       " FunctionTool(name='send_html_email', description='Send out an email with the given subject and HTML body to all sales prospects', params_json_schema={'properties': {'subject': {'title': 'Subject', 'type': 'string'}, 'html_body': {'title': 'Html Body', 'type': 'string'}}, 'required': ['subject', 'html_body'], 'title': 'send_html_email_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x0000013FD8A06340>, strict_json_schema=True, is_enabled=True)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Agents as Handoffs. \n",
    "subject_instructions = \"You can write a subject for a cold sales email. \\\n",
    "You are given a message and you need to write a subject for an email that is likely to get a response.\"\n",
    "\n",
    "html_instructions = \"You can convert a text email body to an HTML email body. \\\n",
    "You are given a text email body which might have some markdown \\\n",
    "and you need to convert it to an HTML email body with simple, clear, compelling layout and design.\"\n",
    "\n",
    "subject_writer = Agent(name=\"Subject Writer\", instructions=subject_instructions, model=\"gpt-4o-mini\")\n",
    "subject_writer_tool = subject_writer.as_tool(tool_name=\"Subject Writer\", tool_description=\"Write a subject for cold sales email\")\n",
    "\n",
    "html_convertor = Agent(name=\"Html converter\", instructions=html_instructions, model=\"gpt-4o-mini\")\n",
    "html_convertor_tool = html_convertor.as_tool(tool_name=\"Html convertor\", tool_description=\"Convert a text email body to an HTML email body\")\n",
    "\n",
    "@function_tool\n",
    "def send_html_email(subject: str, html_body: str) -> Dict[str, str]:\n",
    "    \"\"\" Send out an email with the given subject and HTML body to all sales prospects \"\"\"\n",
    "    sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "    from_email = Email(\"jayantms@gmail.com\")  # Change to your verified sender\n",
    "    to_email = To(\"jayantms@gmail.com\")  # Change to your recipient\n",
    "    content = Content(\"text/html\", html_body)\n",
    "    mail = Mail(from_email, to_email, subject, content).get()\n",
    "    sg.client.mail.send.post(request_body=mail)\n",
    "    return {\"status\": \"success\"}\n",
    "\n",
    "tools = [subject_writer_tool, html_convertor_tool, send_html_email]\n",
    "tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3eefc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions =\"You are an email formatter and sender. You receive the body of an email to be sent. \\\n",
    "You first use the subject_writer tool to write a subject for the email, then use the html_converter tool to convert the body to HTML. \\\n",
    "Finally, you use the send_html_email tool to send the email with the subject and HTML body.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0f0793ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "emailer_agent = Agent(\n",
    "    name=\"Email Manager\",\n",
    "    instructions=instructions,\n",
    "    tools=tools,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    handoff_description=\"Convert an email to HTML and send it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c537d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FunctionTool(name='agent1', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'agent1_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x0000013FD8A04FE0>, strict_json_schema=True, is_enabled=True), FunctionTool(name='agent2', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'agent2_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x0000013FD8A05300>, strict_json_schema=True, is_enabled=True), FunctionTool(name='agent3', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'agent3_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x0000013FD8905E40>, strict_json_schema=True, is_enabled=True)]\n",
      "[Agent(name='Email Manager', instructions='You are an email formatter and sender. You receive the body of an email to be sent. You first use the subject_writer tool to write a subject for the email, then use the html_converter tool to convert the body to HTML. Finally, you use the send_html_email tool to send the email with the subject and HTML body.', prompt=None, handoff_description='Convert an email to HTML and send it', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[FunctionTool(name='Subject Writer', description='Write a subject for cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'Subject Writer_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x0000013FD8A242C0>, strict_json_schema=True, is_enabled=True), FunctionTool(name='Html convertor', description='Convert a text email body to an HTML email body', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'Html convertor_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x0000013FD8A07EC0>, strict_json_schema=True, is_enabled=True), FunctionTool(name='send_html_email', description='Send out an email with the given subject and HTML body to all sales prospects', params_json_schema={'properties': {'subject': {'title': 'Subject', 'type': 'string'}, 'html_body': {'title': 'Html Body', 'type': 'string'}}, 'required': ['subject', 'html_body'], 'title': 'send_html_email_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x0000013FD8A06340>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)]\n"
     ]
    }
   ],
   "source": [
    "tools = [tool1, tool2, tool3]\n",
    "handoffs = [emailer_agent]\n",
    "print(tools)\n",
    "print(handoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1d0dfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting response: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': 'tools[0].name', 'code': 'invalid_value'}}. (request_id: req_48b39260267640e8b7200fa3ade376bc)\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid 'tools[0].name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': 'tools[0].name', 'code': 'invalid_value'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m message = \u001b[33m\"\u001b[39m\u001b[33mSend out a cold sales email addressed to Dear CEO from Alice\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trace(\u001b[33m\"\u001b[39m\u001b[33mAutomated SDR\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(sales_manager, message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Jayant_HOME_Folder\\Basics\\Python\\Agentic_AI_Ed\\agents\\.venv\\Lib\\site-packages\\agents\\run.py:199\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run a workflow starting at the given agent. The agent will run in a loop until a final\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[33;03moutput is generated. The loop runs like so:\u001b[39;00m\n\u001b[32m    174\u001b[39m \u001b[33;03m1. The agent is invoked with the given input.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    196\u001b[39m \u001b[33;03m    agent. Agents may perform handoffs, so we don't know the specific type of the output.\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    198\u001b[39m runner = DEFAULT_AGENT_RUNNER\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m runner.run(\n\u001b[32m    200\u001b[39m     starting_agent,\n\u001b[32m    201\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    202\u001b[39m     context=context,\n\u001b[32m    203\u001b[39m     max_turns=max_turns,\n\u001b[32m    204\u001b[39m     hooks=hooks,\n\u001b[32m    205\u001b[39m     run_config=run_config,\n\u001b[32m    206\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    207\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Jayant_HOME_Folder\\Basics\\Python\\Agentic_AI_Ed\\agents\\.venv\\Lib\\site-packages\\agents\\run.py:417\u001b[39m, in \u001b[36mAgentRunner.run\u001b[39m\u001b[34m(self, starting_agent, input, **kwargs)\u001b[39m\n\u001b[32m    395\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    396\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_input_guardrails(\n\u001b[32m    397\u001b[39m             starting_agent,\n\u001b[32m   (...)\u001b[39m\u001b[32m    414\u001b[39m         ),\n\u001b[32m    415\u001b[39m     )\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_single_turn(\n\u001b[32m    418\u001b[39m         agent=current_agent,\n\u001b[32m    419\u001b[39m         all_tools=all_tools,\n\u001b[32m    420\u001b[39m         original_input=original_input,\n\u001b[32m    421\u001b[39m         generated_items=generated_items,\n\u001b[32m    422\u001b[39m         hooks=hooks,\n\u001b[32m    423\u001b[39m         context_wrapper=context_wrapper,\n\u001b[32m    424\u001b[39m         run_config=run_config,\n\u001b[32m    425\u001b[39m         should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    426\u001b[39m         tool_use_tracker=tool_use_tracker,\n\u001b[32m    427\u001b[39m         previous_response_id=previous_response_id,\n\u001b[32m    428\u001b[39m     )\n\u001b[32m    429\u001b[39m should_run_agent_start_hooks = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    431\u001b[39m model_responses.append(turn_result.model_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Jayant_HOME_Folder\\Basics\\Python\\Agentic_AI_Ed\\agents\\.venv\\Lib\\site-packages\\agents\\run.py:905\u001b[39m, in \u001b[36mAgentRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    902\u001b[39m \u001b[38;5;28minput\u001b[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001b[32m    903\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n\u001b[32m    906\u001b[39m     agent,\n\u001b[32m    907\u001b[39m     system_prompt,\n\u001b[32m    908\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    909\u001b[39m     output_schema,\n\u001b[32m    910\u001b[39m     all_tools,\n\u001b[32m    911\u001b[39m     handoffs,\n\u001b[32m    912\u001b[39m     context_wrapper,\n\u001b[32m    913\u001b[39m     run_config,\n\u001b[32m    914\u001b[39m     tool_use_tracker,\n\u001b[32m    915\u001b[39m     previous_response_id,\n\u001b[32m    916\u001b[39m     prompt_config,\n\u001b[32m    917\u001b[39m )\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n\u001b[32m    920\u001b[39m     agent=agent,\n\u001b[32m    921\u001b[39m     original_input=original_input,\n\u001b[32m   (...)\u001b[39m\u001b[32m    930\u001b[39m     tool_use_tracker=tool_use_tracker,\n\u001b[32m    931\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Jayant_HOME_Folder\\Basics\\Python\\Agentic_AI_Ed\\agents\\.venv\\Lib\\site-packages\\agents\\run.py:1066\u001b[39m, in \u001b[36mAgentRunner._get_new_response\u001b[39m\u001b[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, context_wrapper, run_config, tool_use_tracker, previous_response_id, prompt_config)\u001b[39m\n\u001b[32m   1063\u001b[39m model_settings = agent.model_settings.resolve(run_config.model_settings)\n\u001b[32m   1064\u001b[39m model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m model.get_response(\n\u001b[32m   1067\u001b[39m     system_instructions=system_prompt,\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1069\u001b[39m     model_settings=model_settings,\n\u001b[32m   1070\u001b[39m     tools=all_tools,\n\u001b[32m   1071\u001b[39m     output_schema=output_schema,\n\u001b[32m   1072\u001b[39m     handoffs=handoffs,\n\u001b[32m   1073\u001b[39m     tracing=get_model_tracing_impl(\n\u001b[32m   1074\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001b[32m   1075\u001b[39m     ),\n\u001b[32m   1076\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m   1077\u001b[39m     prompt=prompt_config,\n\u001b[32m   1078\u001b[39m )\n\u001b[32m   1080\u001b[39m context_wrapper.usage.add(new_response.usage)\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Jayant_HOME_Folder\\Basics\\Python\\Agentic_AI_Ed\\agents\\.venv\\Lib\\site-packages\\agents\\models\\openai_responses.py:82\u001b[39m, in \u001b[36mOpenAIResponsesModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id, prompt)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m response_span(disabled=tracing.is_disabled()) \u001b[38;5;28;01mas\u001b[39;00m span_response:\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m     83\u001b[39m             system_instructions,\n\u001b[32m     84\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m     85\u001b[39m             model_settings,\n\u001b[32m     86\u001b[39m             tools,\n\u001b[32m     87\u001b[39m             output_schema,\n\u001b[32m     88\u001b[39m             handoffs,\n\u001b[32m     89\u001b[39m             previous_response_id,\n\u001b[32m     90\u001b[39m             stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     91\u001b[39m             prompt=prompt,\n\u001b[32m     92\u001b[39m         )\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n\u001b[32m     95\u001b[39m             logger.debug(\u001b[33m\"\u001b[39m\u001b[33mLLM responded\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Jayant_HOME_Folder\\Basics\\Python\\Agentic_AI_Ed\\agents\\.venv\\Lib\\site-packages\\agents\\models\\openai_responses.py:256\u001b[39m, in \u001b[36mOpenAIResponsesModel._fetch_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, previous_response_id, stream, prompt)\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    246\u001b[39m     logger.debug(\n\u001b[32m    247\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling LLM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with input:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson.dumps(list_input,\u001b[38;5;250m \u001b[39mindent=\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    253\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrevious response id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprevious_response_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    254\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.responses.create(\n\u001b[32m    257\u001b[39m     previous_response_id=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(previous_response_id),\n\u001b[32m    258\u001b[39m     instructions=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(system_instructions),\n\u001b[32m    259\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    260\u001b[39m     \u001b[38;5;28minput\u001b[39m=list_input,\n\u001b[32m    261\u001b[39m     include=converted_tools.includes,\n\u001b[32m    262\u001b[39m     tools=converted_tools.tools,\n\u001b[32m    263\u001b[39m     prompt=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(prompt),\n\u001b[32m    264\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.temperature),\n\u001b[32m    265\u001b[39m     top_p=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.top_p),\n\u001b[32m    266\u001b[39m     truncation=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.truncation),\n\u001b[32m    267\u001b[39m     max_output_tokens=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.max_tokens),\n\u001b[32m    268\u001b[39m     tool_choice=tool_choice,\n\u001b[32m    269\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    270\u001b[39m     stream=stream,\n\u001b[32m    271\u001b[39m     extra_headers={**_HEADERS, **(model_settings.extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})},\n\u001b[32m    272\u001b[39m     extra_query=model_settings.extra_query,\n\u001b[32m    273\u001b[39m     extra_body=model_settings.extra_body,\n\u001b[32m    274\u001b[39m     text=response_format,\n\u001b[32m    275\u001b[39m     store=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.store),\n\u001b[32m    276\u001b[39m     reasoning=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.reasoning),\n\u001b[32m    277\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.metadata),\n\u001b[32m    278\u001b[39m     **(model_settings.extra_args \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    279\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Jayant_HOME_Folder\\Basics\\Python\\Agentic_AI_Ed\\agents\\.venv\\Lib\\site-packages\\openai\\resources\\responses\\responses.py:1918\u001b[39m, in \u001b[36mAsyncResponses.create\u001b[39m\u001b[34m(self, background, include, input, instructions, max_output_tokens, metadata, model, parallel_tool_calls, previous_response_id, prompt, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1887\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1888\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1889\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1916\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1917\u001b[39m ) -> Response | AsyncStream[ResponseStreamEvent]:\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   1919\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/responses\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1920\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   1921\u001b[39m             {\n\u001b[32m   1922\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mbackground\u001b[39m\u001b[33m\"\u001b[39m: background,\n\u001b[32m   1923\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude\u001b[39m\u001b[33m\"\u001b[39m: include,\n\u001b[32m   1924\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1925\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m\"\u001b[39m: instructions,\n\u001b[32m   1926\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_output_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_output_tokens,\n\u001b[32m   1927\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   1928\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   1929\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   1930\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprevious_response_id\u001b[39m\u001b[33m\"\u001b[39m: previous_response_id,\n\u001b[32m   1931\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt,\n\u001b[32m   1932\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m: reasoning,\n\u001b[32m   1933\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   1934\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   1935\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   1936\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   1937\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: text,\n\u001b[32m   1938\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   1939\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   1940\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   1941\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtruncation\u001b[39m\u001b[33m\"\u001b[39m: truncation,\n\u001b[32m   1942\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   1943\u001b[39m             },\n\u001b[32m   1944\u001b[39m             response_create_params.ResponseCreateParamsStreaming\n\u001b[32m   1945\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   1946\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m response_create_params.ResponseCreateParamsNonStreaming,\n\u001b[32m   1947\u001b[39m         ),\n\u001b[32m   1948\u001b[39m         options=make_request_options(\n\u001b[32m   1949\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   1950\u001b[39m         ),\n\u001b[32m   1951\u001b[39m         cast_to=Response,\n\u001b[32m   1952\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1953\u001b[39m         stream_cls=AsyncStream[ResponseStreamEvent],\n\u001b[32m   1954\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Jayant_HOME_Folder\\Basics\\Python\\Agentic_AI_Ed\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1784\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1770\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1772\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1779\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1780\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1781\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1782\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1783\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Jayant_HOME_Folder\\Basics\\Python\\Agentic_AI_Ed\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1584\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1581\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1583\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1584\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1586\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1588\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': 'tools[0].name', 'code': 'invalid_value'}}"
     ]
    }
   ],
   "source": [
    "# Improved instructions thanks to student Guillermo F.\n",
    "\n",
    "sales_manager_instructions = \"\"\"\n",
    "You are a Sales Manager at ComplAI. Your goal is to find the single best cold sales email using the sales_agent tools.\n",
    " \n",
    "Follow these steps carefully:\n",
    "1. Generate Drafts: Use all three sales_agent tools to generate three different email drafts. Do not proceed until all three drafts are ready.\n",
    " \n",
    "2. Evaluate and Select: Review the drafts and choose the single best email using your judgment of which one is most effective.\n",
    "You can use the tools multiple times if you're not satisfied with the results from the first try.\n",
    " \n",
    "3. Handoff for Sending: Pass ONLY the winning email draft to the 'Email Manager' agent. The Email Manager will take care of formatting and sending.\n",
    " \n",
    "Crucial Rules:\n",
    "- You must use the sales agent tools to generate the drafts ‚Äî do not write them yourself.\n",
    "- You must hand off exactly ONE email to the Email Manager ‚Äî never more than one.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sales_manager = Agent(\n",
    "    name=\"Sales Manager\",\n",
    "    instructions=sales_manager_instructions,\n",
    "    tools=tools,\n",
    "    handoffs=handoffs,\n",
    "    model=\"gpt-4o-mini\")\n",
    "\n",
    "message = \"Send out a cold sales email addressed to Dear CEO from Alice\"\n",
    "\n",
    "with trace(\"Automated SDR\"):\n",
    "    result = await Runner.run(sales_manager, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1883cd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
